{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46db966a-e421-4922-be82-bf27900e310a",
   "metadata": {},
   "source": [
    "### Loading Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eec768a-9046-48e7-afd8-35743fd87c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from src.generators.tvae_generator import TVAESynthesizerWrapper\n",
    "from src.generators.ctgan_generator import CTGANSynthesizerWrapper\n",
    "from src.generators.ctabgan_generator_tofix import CTABGANSynthesizerWrapper\n",
    "from src.generators.great_generator import GREATSynthesizerWrapper\n",
    "from src.generators.rtf_generator import RTFGeneratorWrapper\n",
    "from src.utils.postprocess import match_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f65488a-d491-43a7-a234-72553a848d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, List, Dict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4bdda5-99f2-4101-ace0-c1993de92d62",
   "metadata": {},
   "source": [
    "### Importing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa16083d-6131-4d8d-87e6-1c7e932626a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed training data\n",
    "df = pd.read_csv(\"../data/raw/stroke.csv\")\n",
    "df.drop(columns=['id'],inplace=True)\n",
    "dataset_name = \"stroke\"\n",
    "# Output log file\n",
    "log_path = Path(\"../results/logs/synthetic_finetuning_log_stroke.csv\")\n",
    "log_path.parent.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c6ba02-a532-4aa2-b1d6-b360dd97ea27",
   "metadata": {},
   "source": [
    "### Parameters to Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe21bce5-3e03-4141-ad31-32c9161ef46a",
   "metadata": {},
   "outputs": [],
   "source": [
    "generators = {\n",
    "    \"tvae\": TVAESynthesizerWrapper(output_dir=\"../data/synthetic/tvae\"),\n",
    "    \"ctgan\": CTGANSynthesizerWrapper(output_dir=\"../data/synthetic/ctgan\"),\n",
    "    \"ctabgan\": lambda: CTABGANSynthesizerWrapper(output_dir=\"../data/synthetic/ctabgan\", num_experiments=1),\n",
    "    \"great\": GREATSynthesizerWrapper(output_dir=\"../data/synthetic/great\"),\n",
    "    \"rtf\": RTFGeneratorWrapper(output_dir=\"../data/synthetic/rtf\"),\n",
    "}\n",
    "\n",
    "# Light param grids \n",
    "param_grids = {\n",
    "    \"ctgan\": [\n",
    "        {\"epochs\": 100, \"batch_size\": 128, \"embedding_dim\": 128, \"pac\": 1, \"generator_lr\": 2e-4, \"discriminator_lr\": 2e-4},\n",
    "        {\"epochs\": 100, \"batch_size\": 128, \"embedding_dim\": 128, \"pac\": 2, \"generator_lr\": 2e-4, \"discriminator_lr\": 2e-4},\n",
    "        {\"epochs\": 100, \"batch_size\": 256, \"embedding_dim\": 128, \"pac\": 1, \"generator_lr\": 2e-4, \"discriminator_lr\": 2e-4},\n",
    "        {\"epochs\": 100, \"batch_size\": 256, \"embedding_dim\": 128, \"pac\": 2, \"generator_lr\": 2e-4, \"discriminator_lr\": 2e-4},\n",
    "        {\"epochs\": 300, \"batch_size\": 256, \"embedding_dim\": 128, \"pac\": 1, \"generator_lr\": 2e-4, \"discriminator_lr\": 2e-4},\n",
    "        {\"epochs\": 300, \"batch_size\": 256, \"embedding_dim\": 128, \"pac\": 2, \"generator_lr\": 2e-4, \"discriminator_lr\": 2e-4},\n",
    "    ], \n",
    "    \"tvae\": [\n",
    "        {\"epochs\": 100, \"compress_dims\": (128,128), \"decompress_dims\": (128,128)},\n",
    "        {\"epochs\": 200, \"compress_dims\": (128,128), \"decompress_dims\": (128,128)},\n",
    "        {\"epochs\": 100, \"compress_dims\": (64,64), \"decompress_dims\": (64,64)},\n",
    "        {\"epochs\": 200, \"compress_dims\": (64,64), \"decompress_dims\": (64,64)},\n",
    "    ],\n",
    "    \"ctabgan\": [\n",
    "        {\"epochs\": 100},\n",
    "        {\"epochs\": 150},\n",
    "        {\"epochs\": 200},\n",
    "        {\"epochs\": 100, \"generator_dim\": (128, 128), \"discriminator_dim\": (128, 128)},\n",
    "        {\"epochs\": 150, \"generator_dim\": (128, 128), \"discriminator_dim\": (128, 128)},\n",
    "        {\"epochs\": 100, \"generator_dim\": (256, 256), \"discriminator_dim\": (256, 256)},\n",
    "    ],\n",
    "    \"great\": [\n",
    "        {\"llm\": \"distilgpt2\", \"batch_size\": 32, \"epochs\": 40, \"save_steps\": 10000, \"guided_sampling\": False},\n",
    "        {\"llm\": \"distilgpt2\", \"batch_size\": 64, \"epochs\": 40, \"save_steps\": 10000, \"guided_sampling\": False},\n",
    "        {\"llm\": \"distilgpt2\", \"batch_size\": 32, \"epochs\": 80, \"save_steps\": 10000, \"guided_sampling\": False},\n",
    "        {\"llm\": \"distilgpt2\", \"batch_size\": 64, \"epochs\": 80, \"save_steps\": 10000, \"guided_sampling\": False},\n",
    "    ],\n",
    "\n",
    "    \"rtf\": [\n",
    "        {\"batch_size\": 64, \"epochs\": 30, \"gradient_accumulation_steps\": 4, \"mask_rate\": 0.00, \"logging_steps\": 100},\n",
    "        {\"batch_size\": 32, \"epochs\": 30, \"gradient_accumulation_steps\": 8, \"mask_rate\": 0.05, \"logging_steps\": 100},\n",
    "        {\"batch_size\": 96, \"epochs\": 20, \"gradient_accumulation_steps\": 2, \"mask_rate\": 0.00, \"logging_steps\": 100},\n",
    "        {\"batch_size\": 32, \"epochs\": 40, \"gradient_accumulation_steps\": 8, \"mask_rate\": 0.00, \"logging_steps\": 100},\n",
    "        {\"batch_size\": 64, \"epochs\": 30, \"gradient_accumulation_steps\": 4, \"mask_rate\": 0.10, \"logging_steps\": 100},\n",
    "        {\"batch_size\": 64, \"epochs\": 25, \"gradient_accumulation_steps\": 4, \"mask_rate\": 0.05, \"logging_steps\": 100},\n",
    "    ]\n",
    "\n",
    "}\n",
    "\n",
    "# CTABGAN configs \n",
    "ctabgan_configs = {\n",
    "    \"diabetes\": {\n",
    "        \"raw_csv_path\": \"../data/processed/diabetes_train.csv\",\n",
    "        \"categorical_columns\": ['gender', 'hypertension', 'heart_disease', 'smoking_history', 'diabetes'],\n",
    "        \"log_columns\": [],\n",
    "        \"mixed_columns\": {},\n",
    "        \"general_columns\": ['bmi', 'HbA1c_level'],\n",
    "        \"non_categorical_columns\": [],\n",
    "        \"integer_columns\": ['age', 'blood_glucose_level'],\n",
    "        \"problem_type\": {\"Classification\": 'diabetes'}\n",
    "    },\n",
    "    \"stroke\": {\n",
    "        \"raw_csv_path\": \"../data/processed/stroke_train.csv\",\n",
    "        \"categorical_columns\": ['gender', 'hypertension', 'heart_disease', 'ever_married', 'work_type', 'Residence_type', 'smoking_status', 'stroke'],\n",
    "        \"log_columns\": [],\n",
    "        \"mixed_columns\": {},\n",
    "        \"general_columns\": ['bmi'],\n",
    "        \"non_categorical_columns\": [],\n",
    "        \"integer_columns\": ['age', 'avg_glucose_level'],\n",
    "        \"problem_type\": {\"Classification\": 'stroke'}\n",
    "    },\n",
    "    \"cirrhosis\": {\n",
    "        \"raw_csv_path\": \"../data/processed/cirrhosis_train.csv\",\n",
    "        \"categorical_columns\": ['Sex', 'Ascites', 'Hepatomegaly', 'Spiders', 'Edema', 'Drug', 'Status', 'Stage'],\n",
    "        \"log_columns\": [],\n",
    "        \"mixed_columns\": {},\n",
    "        \"general_columns\": ['Cholesterol', 'Albumin', 'Copper', 'Alk_Phos', 'SGOT', 'Tryglicerides', 'Platelets', 'Prothrombin'],\n",
    "        \"non_categorical_columns\": [],\n",
    "        \"integer_columns\": ['N_Days', 'Age'],\n",
    "        \"problem_type\": {\"Classification\": 'Status'}\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff39a0d-4392-47dc-8355-9278769fc3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator function\n",
    "\n",
    "def _ml_utility_valsplit(\n",
    "    real_df: pd.DataFrame,\n",
    "    synth_df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    test_size: float = 0.30,\n",
    "    random_state: int = 42,\n",
    "    max_synth_rows: int = 5000,\n",
    ") -> Optional[float]:\n",
    "    \"\"\"Train on synthetic, validate on a single real holdout split.\"\"\"\n",
    "    if target_col not in real_df.columns or target_col not in synth_df.columns:\n",
    "        return None\n",
    "\n",
    "    # numeric-only features (keep consistent with your current approach)\n",
    "    X_real = real_df.drop(columns=[target_col]).select_dtypes(include=[np.number])\n",
    "    y_real = real_df[target_col]\n",
    "    X_syn  = synth_df.drop(columns=[target_col]).select_dtypes(include=[np.number])\n",
    "    y_syn  = synth_df[target_col]\n",
    "\n",
    "    # guards\n",
    "    if X_real.shape[1] == 0 or y_real.nunique() < 2 or y_real.nunique() > 20:\n",
    "        return None\n",
    "\n",
    "    # downsample synthetic for speed \n",
    "    if len(X_syn) > max_synth_rows:\n",
    "        idx = np.random.RandomState(random_state).choice(len(X_syn), size=max_synth_rows, replace=False)\n",
    "        X_syn = X_syn.iloc[idx]\n",
    "        y_syn = y_syn.iloc[idx]\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X_real, y_real, test_size=test_size, random_state=random_state, stratify=y_real\n",
    "    )\n",
    "\n",
    "    # Train on synthetic, test on real holdout\n",
    "    clf = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=random_state, n_jobs=-1)\n",
    "    clf.fit(X_syn, y_syn)\n",
    "    pred = clf.predict(X_te)\n",
    "    return float(accuracy_score(y_te, pred))\n",
    "\n",
    "\n",
    "def _ml_utility_kfold(\n",
    "    real_df: pd.DataFrame,\n",
    "    synth_df: pd.DataFrame,\n",
    "    target_col: str,\n",
    "    n_splits: int = 5,\n",
    "    random_state: int = 42,\n",
    "    max_synth_rows_per_fold: int = 3000,\n",
    ") -> Optional[dict]:\n",
    "    \"\"\"Train on synthetic, test on K disjoint real folds; return mean/stdev accuracy.\"\"\"\n",
    "    if target_col not in real_df.columns or target_col not in synth_df.columns:\n",
    "        return None\n",
    "\n",
    "    X_real = real_df.drop(columns=[target_col]).select_dtypes(include=[np.number])\n",
    "    y_real = real_df[target_col]\n",
    "    X_syn  = synth_df.drop(columns=[target_col]).select_dtypes(include=[np.number])\n",
    "    y_syn  = synth_df[target_col]\n",
    "\n",
    "    if X_real.shape[1] == 0 or y_real.nunique() < 2 or y_real.nunique() > 20:\n",
    "        return None\n",
    "\n",
    "    # downsample synthetic once (held fixed across folds for fairness/speed)\n",
    "    if len(X_syn) > max_synth_rows_per_fold:\n",
    "        idx = np.random.RandomState(random_state).choice(len(X_syn), size=max_synth_rows_per_fold, replace=False)\n",
    "        X_syn = X_syn.iloc[idx]\n",
    "        y_syn = y_syn.iloc[idx]\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    fold_scores: List[float] = []\n",
    "\n",
    "    for _, test_idx in skf.split(X_real, y_real):\n",
    "        X_te = X_real.iloc[test_idx]\n",
    "        y_te = y_real.iloc[test_idx]\n",
    "\n",
    "        clf = RandomForestClassifier(n_estimators=50, max_depth=6, random_state=random_state, n_jobs=-1)\n",
    "        clf.fit(X_syn, y_syn)\n",
    "        pred = clf.predict(X_te)\n",
    "        fold_scores.append(accuracy_score(y_te, pred))\n",
    "\n",
    "    return {\n",
    "        \"mean\": float(np.mean(fold_scores)),\n",
    "        \"std\":  float(np.std(fold_scores, ddof=1)) if len(fold_scores) > 1 else 0.0,\n",
    "        \"n_splits\": n_splits\n",
    "    }\n",
    "\n",
    "\n",
    "def evaluate_quick_with_cv(\n",
    "    real_data: pd.DataFrame,\n",
    "    synthetic_data: pd.DataFrame,\n",
    "    target_col: Optional[str] = None,\n",
    "    *,\n",
    "    use_kfold: bool = True,\n",
    "    n_splits: int = 5,\n",
    "    random_state: int = 42,\n",
    "    max_synth_rows: int = 5000,\n",
    ") -> dict:\n",
    "\n",
    "    # 1) shape (30%)\n",
    "    shape_score = 0.30 if real_data.shape[1] == synthetic_data.shape[1] else 0.0\n",
    "\n",
    "    # 2) numeric column means (40%)\n",
    "    mean_score = 0.0\n",
    "    numeric_cols = real_data.select_dtypes(include=[np.number]).columns\n",
    "    if len(numeric_cols) > 0:\n",
    "        diffs = []\n",
    "        for col in numeric_cols:\n",
    "            if col in synthetic_data.columns:\n",
    "                rm = real_data[col].mean()\n",
    "                sm = synthetic_data[col].mean()\n",
    "                if rm != 0:\n",
    "                    diffs.append(abs(rm - sm) / abs(rm))\n",
    "        if diffs:\n",
    "            mean_score = 0.40 * max(0.0, 1.0 - float(np.mean(diffs)))\n",
    "\n",
    "    # 3) ML utility (30%): TSTR on val split or K-fold\n",
    "    ml_score = None\n",
    "    ml_cv = None\n",
    "    if target_col:\n",
    "        if use_kfold:\n",
    "            ml_cv = _ml_utility_kfold(real_data, synthetic_data, target_col, n_splits=n_splits, random_state=random_state)\n",
    "            if ml_cv is not None:\n",
    "                ml_score = 0.30 * ml_cv[\"mean\"]\n",
    "        else:\n",
    "            acc = _ml_utility_valsplit(real_data, synthetic_data, target_col, random_state=random_state, max_synth_rows=max_synth_rows)\n",
    "            if acc is not None:\n",
    "                ml_score = 0.30 * acc\n",
    "\n",
    "    overall = shape_score + mean_score + (ml_score or 0.0)\n",
    "    overall = min(1.0, float(overall))\n",
    "\n",
    "    return {\n",
    "        \"overall_quick_score\": overall,\n",
    "        \"shape_component\": shape_score,\n",
    "        \"means_component\": mean_score,\n",
    "        \"ml_component\": ml_score if ml_score is not None else 0.0,\n",
    "        \"ml_cv\": ml_cv, \n",
    "    }\n",
    "\n",
    "\n",
    "# Wrapper Calling\n",
    "def _call_wrapper(generator_obj_or_factory, name, df, dataset_name, *, params, ctabgan_configs):\n",
    "    wrapper = generator_obj_or_factory() if callable(generator_obj_or_factory) else generator_obj_or_factory\n",
    "    kwargs = {}\n",
    "    if name.lower() == \"ctabgan\" and ctabgan_configs is not None:\n",
    "        cfg = ctabgan_configs.get(dataset_name.lower())\n",
    "        if cfg is None:\n",
    "            raise ValueError(f\"No CTABGAN config for dataset '{dataset_name}'.\")\n",
    "        kwargs[\"ctabgan_config\"] = cfg\n",
    "\n",
    "    try:\n",
    "        return wrapper.fit_and_generate(df, dataset_name, **params, **kwargs)\n",
    "    except TypeError:\n",
    "        try:\n",
    "            return wrapper.fit_and_generate(df, dataset_name, synth_params=params, **kwargs)\n",
    "        except TypeError:\n",
    "            print(f\"  Note: '{name}' wrapper did not accept params; using defaults.\")\n",
    "            return wrapper.fit_and_generate(df, dataset_name, **kwargs)\n",
    "\n",
    "\n",
    "#  Grid search with validation / K-fold\n",
    "def light_grid_search_with_wrappers(\n",
    "    df: pd.DataFrame,\n",
    "    dataset_name: str,\n",
    "    generators: Dict[str, object],\n",
    "    param_grids: Dict[str, List[dict]],\n",
    "    *,\n",
    "    target_col: Optional[str] = None,\n",
    "    n_samples: int = 1000,\n",
    "    ctabgan_configs: Optional[dict] = None,\n",
    "    models_to_test: Optional[List[str]] = None,\n",
    "    # new options:\n",
    "    use_kfold: bool = True,\n",
    "    n_splits: int = 5,\n",
    "    random_state: int = 42,\n",
    "    max_synth_rows_for_eval: int = 5000,\n",
    "):\n",
    "    \"\"\"\n",
    "    Runs a light grid search with optional K-fold utility evaluation (Train on Synthetic, Test on Real).\n",
    "    \"\"\"\n",
    "    if models_to_test is None:\n",
    "        models_to_test = list(generators.keys())\n",
    "\n",
    "    results = []\n",
    "    print(f\"Grid search on dataset '{dataset_name}' | models: {models_to_test}\")\n",
    "\n",
    "    for name in models_to_test:\n",
    "        if name not in generators:\n",
    "            print(f\"Skipping '{name}': not in generators dict.\")\n",
    "            continue\n",
    "        if name not in param_grids:\n",
    "            print(f\"Skipping '{name}': no param grid provided.\")\n",
    "            continue\n",
    "\n",
    "        print(f\"\\n=== {name.upper()} ===\")\n",
    "        for i, params in enumerate(param_grids[name], start=1):\n",
    "            print(f\"[{i}/{len(param_grids[name])}] params={params}\")\n",
    "            t0 = time.time()\n",
    "            try:\n",
    "                synth_df, stats = _call_wrapper(\n",
    "                    generators[name], name, df, dataset_name,\n",
    "                    params=params, ctabgan_configs=ctabgan_configs\n",
    "                )\n",
    "\n",
    "                if len(synth_df) > n_samples:\n",
    "                    synth_df_eval = synth_df.sample(n_samples, random_state=random_state).reset_index(drop=True)\n",
    "                else:\n",
    "                    synth_df_eval = synth_df.reset_index(drop=True)\n",
    "\n",
    "                eval_out = evaluate_quick_with_cv(\n",
    "                    df.reset_index(drop=True),\n",
    "                    synth_df_eval,\n",
    "                    target_col=target_col,\n",
    "                    use_kfold=use_kfold,\n",
    "                    n_splits=n_splits,\n",
    "                    random_state=random_state,\n",
    "                    max_synth_rows=max_synth_rows_for_eval\n",
    "                )\n",
    "                elapsed = time.time() - t0\n",
    "\n",
    "                row = {\n",
    "                    \"generator\": name,\n",
    "                    \"params\": params,\n",
    "                    \"quick_score\": round(eval_out[\"overall_quick_score\"], 4),\n",
    "                    \"shape_comp\": round(eval_out[\"shape_component\"], 4),\n",
    "                    \"means_comp\": round(eval_out[\"means_component\"], 4),\n",
    "                    \"ml_comp\": round(eval_out[\"ml_component\"], 4),\n",
    "                    \"elapsed_s\": round(elapsed, 2),\n",
    "                }\n",
    "                if eval_out[\"ml_cv\"] is not None:\n",
    "                    row.update({\n",
    "                        \"ml_cv_mean\": round(eval_out[\"ml_cv\"][\"mean\"], 4),\n",
    "                        \"ml_cv_std\":  round(eval_out[\"ml_cv\"][\"std\"], 4),\n",
    "                        \"ml_cv_folds\": eval_out[\"ml_cv\"][\"n_splits\"],\n",
    "                    })\n",
    "\n",
    "                results.append(row)\n",
    "                print(f\"  -> quick_score={row['quick_score']:.3f} | ml={row.get('ml_cv_mean', row['ml_comp']):.3f} | time={row['elapsed_s']}s\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"  FAILED: {type(e).__name__}: {str(e)[:200]}\")\n",
    "                continue\n",
    "\n",
    "    # Sort best-first by quick_score then ml utility\n",
    "    results = sorted(\n",
    "        results,\n",
    "        key=lambda r: (-r[\"quick_score\"], -r.get(\"ml_cv_mean\", r[\"ml_comp\"]))\n",
    "    )\n",
    "\n",
    "    print(\"\\nTOP 5:\")\n",
    "    for idx, r in enumerate(results[:5], 1):\n",
    "        ml_val = r.get(\"ml_cv_mean\", r[\"ml_comp\"])\n",
    "        print(f\"#{idx} {r['generator'].upper()} | quick={r['quick_score']:.3f} | ml={ml_val:.3f} | params={r['params']}\")\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0cf8ad-4bd5-47a0-8580-5eb8029e268f",
   "metadata": {},
   "source": [
    "### Running Light Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1234b1b-5d2f-473b-9fec-f00f4498b911",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = light_grid_search_with_wrappers(\n",
    "    df,\n",
    "    dataset_name,\n",
    "    generators=generators,\n",
    "    param_grids=param_grids,\n",
    "    target_col=\"stroke\",             \n",
    "    n_samples=1000,\n",
    "    ctabgan_configs=ctabgan_configs,\n",
    "    models_to_test=[\"ctgan\", \"tvae\", \"ctabgan\", \"great\", \"rtf\"],\n",
    "    models_to_test=[\"ctabgan\"],\n",
    "    use_kfold=True,                  \n",
    "    n_splits=5,\n",
    "    random_state=42\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9078c6-7c12-46e4-9f25-dded98097cd4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (realtab)",
   "language": "python",
   "name": "paper-realtab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
