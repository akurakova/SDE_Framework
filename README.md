# Synthetic Tabular Data Evaluation

This repository contains code for a comprehensive evaluation of six synthetic data generation models on tabular datasets. The evaluation covers **data quality**, **privacy**, **machine learning usability**, and **computational complexity**.

---

## ğŸ“Œ Generative Models Evaluated

- **TVAE** (Tabular Variational Autoencoder)
- **CTGAN** (Conditional Tabular GAN)
- **CTABGAN**
- **GREAT**
- **RTF**
- **TABDDPM**

---

## ğŸ“Š Evaluation Criteria

- **Quality**: Statistical similarity to real data
- **Privacy**: Risk of identity disclosure or memorization
- **ML Usability**: How well models trained on synthetic data perform
- **Computational Complexity**: Time and memory usage

---

## ğŸ“ Project Structure

```
synthetic-eval/
â”‚
â”œâ”€â”€ data/                    # Real and synthetic datasets
â”‚   â”œâ”€â”€ raw/                 # Original datasets
â”‚   â””â”€â”€ synthetic/           # Synthetic datasets
â”‚   â””â”€â”€ processed/           # Preprocessed data for models
â”‚
â”œâ”€â”€ notebooks/               # Jupyter notebooks for analysis
â”‚   â”œâ”€â”€ 01_preprocessing.ipynb
â”‚   â”œâ”€â”€ 02_data_generation.ipynb
â”‚   â”œâ”€â”€ 03_evaluation_quality.ipynb
â”‚   â”œâ”€â”€ 04_evaluation_privacy_MIA.ipynb (Includes duplicates evaluation)
â”‚   â””â”€â”€ 05_TSTR_evaluation.ipynb
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ generators/          # Scripts to train each generative model
â”‚   â”œâ”€â”€ evaluation/          # Evaluation metric implementations
â”‚   â””â”€â”€ utils/               # Preprocessing and helper functions
â”‚
â”œâ”€â”€ results/                 # Logs, figures, and output metrics
â”‚   â”œâ”€â”€ figures/
â”‚   â””â”€â”€ logs/
â”‚
â”œâ”€â”€ environment.yml          # Conda environment for reproducibility
â”œâ”€â”€ LICENSE
â”œâ”€â”€ README.md
â””â”€â”€ .gitignore
```

---

## âš™ï¸ Getting Started

### 1. Clone the repository

```bash
git clone https://github.com/YOUR_USERNAME/synthetic-eval-clean.git
cd synthetic-eval-clean
```

### 2. Create and activate the environment

Using conda:

```bash
conda env create -f environment.yml
conda activate synthetic-eval
```

Or using pip:

```bash
pip install -r requirements.txt
```

---

## ğŸš€ Running the Experiments

Each part of the pipeline is modularized:

### Data Generation

```bash
python src/generation/run_ctgan.py
python src/generation/run_tvae.py
# ... other models
```

### Evaluation

```bash
python src/evaluation/quality.py
python src/evaluation/privacy.py
python src/evaluation/usability.py
```

Notebooks (`notebooks/*.ipynb`) provide visualization and result comparison.

---

## ğŸ§ª Reproducibility Notes

- Random seeds are set where applicable
- All preprocessing is standardized via `src/utils/preprocessing.py`
- Memory profiling is integrated in `complexity.py` using `memory_profiler`

---

## ğŸ“œ License

MIT License

---

## ğŸ™‹â€â™€ï¸ Acknowledgements

This work is part of the research paper:  
**A Comprehensive Evaluation Framework for Synthetic
Medical Tabular Data Generation**  
Submitted to: Journal of Biomedical Informatics, 2025
